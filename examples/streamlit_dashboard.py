"""
Streamlit å‰ç«¯ï¼Œå±•ç¤º OpenDigger ä»“åº“æ•°æ®ã€‚
"""

from pathlib import Path
import sys

try:
    import streamlit as st
    import requests
except ImportError:
    st = None
    requests = None

# å…è®¸ç›´æ¥è¿è¡Œï¼Œå°†é¡¹ç›®æ ¹ç›®å½•åŠ å…¥ sys.pathï¼Œæ–¹ä¾¿å¯¼å…¥ src.*
ROOT = Path(__file__).resolve().parents[1]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))


def main():
    if st is None:
        print("é”™è¯¯: éœ€è¦å®‰è£… streamlit: pip install streamlit")
        return

    st.set_page_config(
        page_title="OpenDigger ä»“åº“æ•°æ®çœ‹æ¿",
        page_icon="ğŸ“Š",
        layout="wide",
    )

    st.title("ğŸ“Š OpenDigger ä»“åº“æ•°æ®çœ‹æ¿")

    # API æœåŠ¡å™¨åœ°å€é…ç½®
    api_base_url = st.sidebar.text_input(
        "API æœåŠ¡å™¨åœ°å€",
        value="http://localhost:8000",
        help="FastAPI æœåŠ¡å™¨çš„åœ°å€",
    )

    # æ¨¡å¼é€‰æ‹©
    data_source_mode = st.sidebar.selectbox(
        "æ•°æ®æºæ¨¡å¼",
        options=["offline", "online"],
        index=0,
        help="offline: ä½¿ç”¨æœ¬åœ°ç¦»çº¿æ•°æ®ï¼ˆå¿«é€Ÿï¼‰\nonline: ä½¿ç”¨åœ¨çº¿APIï¼ˆå®æ—¶ï¼‰",
    )

    # ä»“åº“IDè¾“å…¥ï¼ˆåœ¨çº¿æ¨¡å¼éœ€è¦ï¼‰
    repo_ids_input = None
    if data_source_mode == "online":
        repo_ids_input = st.sidebar.text_area(
            "ä»“åº“IDåˆ—è¡¨ï¼ˆæ¯è¡Œä¸€ä¸ªï¼Œæ ¼å¼ï¼šowner/repoï¼‰",
            value="X-lab2017/open-digger\nalibaba/nacos",
            help="åœ¨çº¿æ¨¡å¼å¿…é¡»æä¾›ä»“åº“ID",
        )

    # æ•°é‡é™åˆ¶
    limit = st.sidebar.slider("è¿”å›æ•°é‡", min_value=1, max_value=100, value=20)

    # åˆ·æ–°æŒ‰é’®
    if st.sidebar.button("ğŸ”„ åˆ·æ–°æ•°æ®", type="primary"):
        st.rerun()

    # æ„å»ºè¯·æ±‚å‚æ•°
    params = {
        "mode": data_source_mode,
        "limit": limit,
    }

    if data_source_mode == "online" and repo_ids_input:
        repo_ids = [line.strip() for line in repo_ids_input.split("\n") if line.strip()]
        params["repo_ids"] = repo_ids

    # è·å–æ•°æ®
    try:
        if requests is None:
            st.error("éœ€è¦å®‰è£… requests: pip install requests")
            return

        response = requests.get(f"{api_base_url}/api/repos", params=params, timeout=30)
        response.raise_for_status()
        data = response.json()
    except requests.exceptions.ConnectionError:
        st.error(f"âŒ æ— æ³•è¿æ¥åˆ°APIæœåŠ¡å™¨: {api_base_url}\n\nè¯·ç¡®ä¿APIæœåŠ¡å™¨æ­£åœ¨è¿è¡Œï¼š\n```bash\npython api_server.py\n```")
        return
    except requests.exceptions.HTTPError as e:
        st.error(f"âŒ APIè¯·æ±‚å¤±è´¥: {e}\n\nå“åº”: {response.text if 'response' in locals() else 'N/A'}")
        return
    except Exception as e:
        st.error(f"âŒ è·å–æ•°æ®å¤±è´¥: {e}")
        return

    mode = data.get("mode", "unknown")
    repos = data.get("repos", [])

    # æ˜¾ç¤ºæ¨¡å¼æ ‡è¯†
    mode_badge = "ğŸŸ¢ ç¦»çº¿æ¨¡å¼" if mode == "offline" else "ğŸ”µ åœ¨çº¿æ¨¡å¼"
    st.info(f"{mode_badge} | å…± {len(repos)} ä¸ªä»“åº“")

    if not repos:
        st.warning("æ²¡æœ‰æ‰¾åˆ°ä»“åº“æ•°æ®")
        return

    # æ’åºé€‰é¡¹
    sort_by = st.selectbox(
        "æ’åºæ–¹å¼",
        options=["composite_score", "active_score", "influence_score", "demand_score"],
        index=0,
    )
    repos_sorted = sorted(repos, key=lambda x: x.get(sort_by, 0), reverse=True)

    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        avg_composite = sum(r.get("composite_score", 0) for r in repos) / len(repos)
        st.metric("å¹³å‡ç»¼åˆåˆ†", f"{avg_composite:.3f}")
    with col2:
        avg_active = sum(r.get("active_score", 0) for r in repos) / len(repos)
        st.metric("å¹³å‡æ´»è·ƒåº¦", f"{avg_active:.3f}")
    with col3:
        avg_influence = sum(r.get("influence_score", 0) for r in repos) / len(repos)
        st.metric("å¹³å‡å½±å“åŠ›", f"{avg_influence:.3f}")
    with col4:
        avg_demand = sum(r.get("demand_score", 0) for r in repos) / len(repos)
        st.metric("å¹³å‡éœ€æ±‚çƒ­åº¦", f"{avg_demand:.3f}")

    # æ•°æ®è¡¨æ ¼
    st.subheader("ğŸ“‹ ä»“åº“åˆ—è¡¨")

    # å‡†å¤‡è¡¨æ ¼æ•°æ®
    table_data = []
    for repo in repos_sorted:
        table_data.append({
            "ä»“åº“ID": repo["repo_id"],
            "åç§°": repo["name"],
            "ç»¼åˆåˆ†": f"{repo['composite_score']:.3f}",
            "æ´»è·ƒåº¦": f"{repo['active_score']:.3f}",
            "å½±å“åŠ›": f"{repo['influence_score']:.3f}",
            "éœ€æ±‚çƒ­åº¦": f"{repo['demand_score']:.3f}",
            "è¯­è¨€": ", ".join(repo.get("languages", [])[:3]),
        })

    st.dataframe(table_data, use_container_width=True)

    # è¯¦ç»†è§†å›¾
    st.subheader("ğŸ“Š è¯¦ç»†è§†å›¾")
    selected_repo_id = st.selectbox(
        "é€‰æ‹©ä»“åº“æŸ¥çœ‹è¯¦æƒ…",
        options=[r["repo_id"] for r in repos_sorted],
    )

    selected_repo = next((r for r in repos if r["repo_id"] == selected_repo_id), None)
    if selected_repo:
        col1, col2 = st.columns(2)

        with col1:
            st.write("**åŸºæœ¬ä¿¡æ¯**")
            st.write(f"- ä»“åº“ID: `{selected_repo['repo_id']}`")
            st.write(f"- åç§°: {selected_repo['name']}")
            st.write(f"- æè¿°: {selected_repo.get('description', 'N/A')}")
            st.write(f"- è¯­è¨€: {', '.join(selected_repo.get('languages', []))}")

        with col2:
            st.write("**è¯„åˆ†æŒ‡æ ‡**")
            st.progress(selected_repo["composite_score"], text=f"ç»¼åˆåˆ†: {selected_repo['composite_score']:.3f}")
            st.progress(selected_repo["active_score"], text=f"æ´»è·ƒåº¦: {selected_repo['active_score']:.3f}")
            st.progress(selected_repo["influence_score"], text=f"å½±å“åŠ›: {selected_repo['influence_score']:.3f}")
            st.progress(selected_repo["demand_score"], text=f"éœ€æ±‚çƒ­åº¦: {selected_repo['demand_score']:.3f}")

        # åŸå§‹æŒ‡æ ‡ï¼ˆä»…ç¦»çº¿æ¨¡å¼ï¼‰
        if selected_repo.get("raw_metrics") and mode == "offline":
            with st.expander("ğŸ“„ åŸå§‹æŒ‡æ ‡æ•°æ®"):
                st.json(selected_repo["raw_metrics"])


if __name__ == "__main__":
    main()

